{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df21fa92",
   "metadata": {},
   "source": [
    "# 객체 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0cabb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\githome\\wn7_DL_rep-main\\sample.png: 480x640 2 persons, 24.1ms\n",
      "Speed: 5.9ms preprocess, 24.1ms inference, 11.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[151, 152, 142],\n",
       "         [152, 153, 143],\n",
       "         [152, 153, 143],\n",
       "         ...,\n",
       "         [186, 184, 176],\n",
       "         [186, 184, 176],\n",
       "         [187, 185, 177]],\n",
       " \n",
       "        [[151, 152, 142],\n",
       "         [152, 153, 143],\n",
       "         [152, 153, 143],\n",
       "         ...,\n",
       "         [187, 185, 177],\n",
       "         [187, 185, 177],\n",
       "         [186, 184, 176]],\n",
       " \n",
       "        [[148, 149, 139],\n",
       "         [150, 151, 141],\n",
       "         [151, 152, 142],\n",
       "         ...,\n",
       "         [187, 185, 177],\n",
       "         [186, 184, 176],\n",
       "         [185, 183, 175]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[114, 117, 108],\n",
       "         [117, 120, 111],\n",
       "         [117, 120, 111],\n",
       "         ...,\n",
       "         [ 75,  86, 106],\n",
       "         [ 79,  90, 110],\n",
       "         [ 81,  92, 112]],\n",
       " \n",
       "        [[114, 117, 108],\n",
       "         [117, 120, 111],\n",
       "         [114, 117, 108],\n",
       "         ...,\n",
       "         [ 71,  82, 102],\n",
       "         [ 74,  85, 105],\n",
       "         [ 79,  90, 110]],\n",
       " \n",
       "        [[115, 118, 109],\n",
       "         [117, 120, 111],\n",
       "         [113, 116, 107],\n",
       "         ...,\n",
       "         [ 68,  79,  99],\n",
       "         [ 70,  81, 101],\n",
       "         [ 77,  88, 108]]], dtype=uint8)\n",
       " orig_shape: (960, 1280)\n",
       " path: 'c:\\\\githome\\\\wn7_DL_rep-main\\\\sample.png'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 5.909999992582016, 'inference': 24.10270000109449, 'postprocess': 11.706999997841194}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')   # pt는 가중치파일\n",
    "result = model('sample.png')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7c7cb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\githome\\wn7_DL_rep-main\\gorani.jpg: 320x640 1 sheep, 21.4ms\n",
      "Speed: 2.6ms preprocess, 21.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9200, device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 바운딩박스, 라벨 출력\n",
    "result = model('gorani.jpg')\n",
    "result[0].boxes[0].conf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4054bdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  4,   4,   4],\n",
       "        [  5,   5,   5],\n",
       "        [  5,   5,   5],\n",
       "        ...,\n",
       "        [ 58, 113,  96],\n",
       "        [ 55, 110,  93],\n",
       "        [ 52, 107,  90]],\n",
       "\n",
       "       [[  4,   4,   4],\n",
       "        [  4,   4,   4],\n",
       "        [  4,   4,   4],\n",
       "        ...,\n",
       "        [ 63, 117, 100],\n",
       "        [ 60, 114,  97],\n",
       "        [ 58, 112,  95]],\n",
       "\n",
       "       [[  3,   3,   3],\n",
       "        [  3,   3,   3],\n",
       "        [  3,   3,   3],\n",
       "        ...,\n",
       "        [ 67, 118, 104],\n",
       "        [ 64, 115, 101],\n",
       "        [ 62, 113,  99]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 84, 188, 147],\n",
       "        [ 97, 194, 154],\n",
       "        [ 95, 186, 147],\n",
       "        ...,\n",
       "        [ 61, 160, 120],\n",
       "        [ 82, 188, 149],\n",
       "        [ 71, 180, 141]],\n",
       "\n",
       "       [[ 75, 181, 140],\n",
       "        [ 79, 187, 145],\n",
       "        [ 71, 183, 141],\n",
       "        ...,\n",
       "        [ 84, 185, 147],\n",
       "        [ 64, 167, 129],\n",
       "        [ 76, 179, 141]],\n",
       "\n",
       "       [[ 71, 177, 136],\n",
       "        [ 71, 179, 137],\n",
       "        [ 59, 171, 129],\n",
       "        ...,\n",
       "        [100, 201, 163],\n",
       "        [ 64, 167, 129],\n",
       "        [ 78, 181, 143]]], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('gorani.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41977d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for box in result[0].boxes:\n",
    "    class_id = box.cls[0]\n",
    "    class_name = model.names[class_id.item()]\n",
    "    \n",
    "    # 신뢰도 점수\n",
    "    conf = float(box.conf[0])\n",
    "    \n",
    "    # 바운딩 박스\n",
    "    coords = box.xyxy[0].tolist()\n",
    "    x1, y1, x2, y2 = map(int, coords)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, f'{class_name} {conf:.4f}',\n",
    "                (x1, y1-10), cv2.FONT_HERSHEY_PLAIN,\n",
    "                1, (0, 255, 0), 1)\n",
    "\n",
    "# end-for\n",
    "cv2.imshow('yolov8 object detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('detect_result.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28590848",
   "metadata": {},
   "source": [
    "# segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c6b4870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\githome\\wn7_DL_rep-main\\noryangjin.jpeg: 448x640 5 persons, 27.1ms\n",
      "Speed: 3.3ms preprocess, 27.1ms inference, 16.3ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: ultralytics.engine.results.Masks object\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "obb: None\n",
       "orig_img: array([[[199, 190, 177],\n",
       "        [200, 191, 178],\n",
       "        [201, 192, 179],\n",
       "        ...,\n",
       "        [113, 106, 103],\n",
       "        [113, 106, 103],\n",
       "        [114, 107, 104]],\n",
       "\n",
       "       [[200, 191, 178],\n",
       "        [200, 191, 178],\n",
       "        [202, 193, 180],\n",
       "        ...,\n",
       "        [116, 109, 106],\n",
       "        [118, 111, 108],\n",
       "        [119, 112, 109]],\n",
       "\n",
       "       [[201, 192, 179],\n",
       "        [201, 192, 179],\n",
       "        [201, 192, 182],\n",
       "        ...,\n",
       "        [122, 115, 112],\n",
       "        [123, 116, 113],\n",
       "        [122, 115, 112]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 12,  13,  11],\n",
       "        [ 11,  12,  10],\n",
       "        [ 11,  12,  10],\n",
       "        ...,\n",
       "        [ 19,  17,  16],\n",
       "        [ 18,  16,  15],\n",
       "        [ 18,  16,  15]],\n",
       "\n",
       "       [[ 12,  13,  11],\n",
       "        [ 11,  12,  10],\n",
       "        [ 10,  11,   9],\n",
       "        ...,\n",
       "        [ 19,  17,  16],\n",
       "        [ 18,  16,  15],\n",
       "        [ 17,  15,  14]],\n",
       "\n",
       "       [[ 12,  13,  11],\n",
       "        [ 11,  12,  10],\n",
       "        [ 10,  11,   9],\n",
       "        ...,\n",
       "        [ 18,  16,  16],\n",
       "        [ 18,  16,  16],\n",
       "        [ 18,  16,  16]]], dtype=uint8)\n",
       "orig_shape: (400, 600)\n",
       "path: 'c:\\\\githome\\\\wn7_DL_rep-main\\\\noryangjin.jpeg'\n",
       "probs: None\n",
       "save_dir: 'runs\\\\segment\\\\predict'\n",
       "speed: {'preprocess': 3.2550000032642856, 'inference': 27.10689998639282, 'postprocess': 16.324699987308122}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-seg.pt')   # pt는 가중치파일\n",
    "result = model('noryangjin.jpeg')\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bbc7892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_new = cv2.imread('noryangjin.jpeg')\n",
    "overlay = img_new.copy()   # 마스크용\n",
    "\n",
    "for box, mask in zip(result[0].boxes, result[0].masks):\n",
    "    # 마스크 추가\n",
    "    polygon = mask.xy[0].astype(np.int32)\n",
    "    cv2.fillPoly(overlay, [polygon], (0, 255, 0))\n",
    "    \n",
    "    class_id = box.cls[0]\n",
    "    class_name = model.names[class_id.item()]\n",
    "    \n",
    "    # 신뢰도 점수\n",
    "    conf = float(box.conf[0])\n",
    "    \n",
    "    # 바운딩 박스\n",
    "    coords = box.xyxy[0].tolist()\n",
    "    x1, y1, x2, y2 = map(int, coords)\n",
    "    cv2.rectangle(img_new, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img_new, f'{class_name} {conf:.4f}',\n",
    "                (x1, y1-10), cv2.FONT_HERSHEY_PLAIN,\n",
    "                1, (0, 255, 0), 1)\n",
    "\n",
    "# img+overlay 겹쳐서 출력\n",
    "alpha = 0.5\n",
    "final_img = cv2.addWeighted(overlay, alpha, img_new, 1-alpha, 0)\n",
    "\n",
    "# 최종 출력\n",
    "cv2.imshow('yolov8 object segment', final_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('segment_result.jpg', final_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e910e",
   "metadata": {},
   "source": [
    "# 분류\n",
    "# 자세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fca0aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\githome\\wn7_DL_rep-main\\wook.jpg: 384x640 3 persons, 24.2ms\n",
      "Speed: 2.3ms preprocess, 24.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_model = YOLO('yolov8n-pose.pt')\n",
    "pose_result = pose_model('wook.jpg')\n",
    "img = cv2.imread('wook.jpg')\n",
    "\n",
    "kp = pose_result[0].keypoints\n",
    "\n",
    "for man_kp in kp:\n",
    "    for x, y in man_kp.xy[0]:\n",
    "        if x > 0 and y > 0:\n",
    "            cv2.circle(img, (int(x), int(y)), 3, (255, 0, 0), -1)\n",
    "\n",
    "# 최종 출력\n",
    "cv2.imshow('yolov8 object pose', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('pose_result.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb329175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda_yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
